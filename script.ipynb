{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:02:52.867976Z",
     "start_time": "2024-09-03T05:02:51.848078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle \n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd"
   ],
   "id": "a9fc59a24a218c58",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:02:54.015161Z",
     "start_time": "2024-09-03T05:02:53.419187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.config import get_config\n",
    "from baselines.dnnperf import create_sample_graph\n",
    "from scipy.sparse import csr_matrix\n",
    "import dgl\n",
    "from modules.latency_data import get_matrix_and_ops, get_adjacency_and_features\n",
    "args = get_config()\n",
    "graph, label = get_matrix_and_ops([0, 2, 1, 3, 4, 2])\n",
    "graph, features = get_adjacency_and_features(graph, label)\n",
    "graph = graph[1:, 1:]\n",
    "graph = dgl.to_bidirected(dgl.from_scipy(csr_matrix(graph)))\n",
    "key = torch.argmax(torch.tensor(features).long(), dim=1)[1:]\n",
    "graph = create_sample_graph(key, graph, args)"
   ],
   "id": "a62ff180ed59ce80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Type: input\n",
      "Final Node Feature Vector h: tensor([3.0000e+00, 3.0000e+00, 1.2288e+04, 1.2288e+04, 0.0000e+00, 0.0000e+00,\n",
      "        1.6000e+01])\n",
      "\n",
      "Layer Type: ReLUConvBN\n",
      "Final Node Feature Vector h: tensor([0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "        1.6000e+01])\n",
      "\n",
      "Layer Type: ReLUConvBN\n",
      "Final Node Feature Vector h: tensor([0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "        1.6000e+01])\n",
      "\n",
      "Layer Type: ReLUConvBN\n",
      "Final Node Feature Vector h: tensor([0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "        1.6000e+01])\n",
      "\n",
      "Layer Type: ReLUConvBN\n",
      "Final Node Feature Vector h: tensor([1.0000e+00, 3.0000e+00, 1.2288e+04, 5.7600e+04, 1.7280e+03, 7.7760e+05,\n",
      "        1.6000e+01])\n",
      "\n",
      "Layer Type: ReLUConvBN\n",
      "Final Node Feature Vector h: tensor([0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "        1.6000e+01])\n",
      "\n",
      "Layer Type: ReLUConvBN\n",
      "Final Node Feature Vector h: tensor([0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "        1.6000e+01])\n",
      "\n",
      "Layer Type: output\n",
      "Final Node Feature Vector h: tensor([4.0000e+00, 3.0000e+00, 1.2288e+04, 1.2288e+04, 0.0000e+00, 0.0000e+00,\n",
      "        1.6000e+01])\n",
      "\n",
      "tensor([[3.0000e+00, 3.0000e+00, 1.2288e+04, 1.2288e+04, 0.0000e+00, 0.0000e+00,\n",
      "         1.6000e+01],\n",
      "        [0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "         1.6000e+01],\n",
      "        [0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "         1.6000e+01],\n",
      "        [0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "         1.6000e+01],\n",
      "        [1.0000e+00, 3.0000e+00, 1.2288e+04, 5.7600e+04, 1.7280e+03, 7.7760e+05,\n",
      "         1.6000e+01],\n",
      "        [0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "         1.6000e+01],\n",
      "        [0.0000e+00, 3.0000e+00, 1.2288e+04, 6.5536e+04, 1.9200e+02, 9.8304e+04,\n",
      "         1.6000e+01],\n",
      "        [4.0000e+00, 3.0000e+00, 1.2288e+04, 1.2288e+04, 0.0000e+00, 0.0000e+00,\n",
      "         1.6000e+01]])\n",
      "tensor([[2.4414e-04, 2.4414e-04, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3021e-03],\n",
      "        [0.0000e+00, 3.0518e-05, 1.2500e-01, 6.6667e-01, 1.9531e-03, 1.0000e+00,\n",
      "         1.6276e-04],\n",
      "        [0.0000e+00, 3.0518e-05, 1.2500e-01, 6.6667e-01, 1.9531e-03, 1.0000e+00,\n",
      "         1.6276e-04],\n",
      "        [0.0000e+00, 3.0518e-05, 1.2500e-01, 6.6667e-01, 1.9531e-03, 1.0000e+00,\n",
      "         1.6276e-04],\n",
      "        [0.0000e+00, 2.5720e-06, 1.5801e-02, 7.4073e-02, 2.2209e-03, 1.0000e+00,\n",
      "         1.9290e-05],\n",
      "        [0.0000e+00, 3.0518e-05, 1.2500e-01, 6.6667e-01, 1.9531e-03, 1.0000e+00,\n",
      "         1.6276e-04],\n",
      "        [0.0000e+00, 3.0518e-05, 1.2500e-01, 6.6667e-01, 1.9531e-03, 1.0000e+00,\n",
      "         1.6276e-04],\n",
      "        [3.2552e-04, 2.4414e-04, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.3021e-03]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T04:03:54.423176Z",
     "start_time": "2024-09-03T04:03:54.418990Z"
    }
   },
   "cell_type": "code",
   "source": "graph.ndata['h']",
   "id": "872e0424b6546d37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7500, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils.utils import makedir\n",
    "import os\n",
    "address = './results/ours/only_embed/log'\n",
    "makedir('results')\n",
    "# 打开输出文件\n",
    "with open('./results/output.txt', 'w') as ans:\n",
    "    # 获取目标目录中的所有文件\n",
    "    all_result = os.listdir(address)\n",
    "    \n",
    "    # 遍历所有文件\n",
    "    for filename in all_result:\n",
    "        # 构建文件路径\n",
    "        file_path = os.path.join(address, filename)\n",
    "        \n",
    "        # 打开并读取文件内容\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "            # 打印文件内容\n",
    "            print(content)\n",
    "            \n",
    "            # 将文件内容写入输出文件，添加一些格式\n",
    "            ans.write(f\"Content of {filename}:\\n\")\n",
    "            ans.write(content)\n",
    "            ans.write(\"\\n\\n\")"
   ],
   "id": "c4e2bb0716339ef7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T13:02:51.301164Z",
     "start_time": "2024-07-28T13:02:51.299678Z"
    }
   },
   "cell_type": "code",
   "source": "import pickle ",
   "id": "f11bd60e5fcaf069",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T08:25:41.929666Z",
     "start_time": "2024-08-27T08:25:41.925003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_closest_power_of_2(train_size, percentage=0.10):\n",
    "    # 计算目标 batch size\n",
    "    target_bs = int(train_size * percentage)\n",
    "    \n",
    "    # 定义 2 的幂次序列\n",
    "    powers_of_2 = [2**i for i in range(1, 9)]  # 2, 4, 8, ..., 256\n",
    "\n",
    "    # 找到最接近的 2 的幂次\n",
    "    closest_bs = min(powers_of_2, key=lambda x: abs(x - target_bs))\n",
    "    \n",
    "    return closest_bs\n",
    "\n",
    "# 假设 args 包含 train_size\n",
    "class Args:\n",
    "    def __init__(self, train_size):\n",
    "        self.train_size = train_size\n",
    "\n",
    "args = Args(train_size=100)\n",
    "\n",
    "# 找到最接近的 batch size\n",
    "bs = find_closest_power_of_2(args.train_size)\n",
    "\n",
    "print(f'最佳 batch size 为: {bs}')"
   ],
   "id": "4fb48f8a2301cfe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 batch size 为: 8\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T14:01:24.479700Z",
     "start_time": "2024-08-23T14:01:24.475111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open('./agu/4090.pkl', 'rb') as f:\n",
    "    print(pickle.load(f))\n",
    "with open('./agu/3080.pkl', 'rb') as f:\n",
    "    print(pickle.load(f))\n",
    "# with open('./agu/1080Ti.pkl', 'rb') as f:\n",
    "#     print(pickle.load(f))\n",
    "with open('agu/1080Ti.pkl', 'rb') as f:\n",
    "    print(pickle.load(f))"
   ],
   "id": "59f767b47c55e11c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5120, 2.2, 12.0, 256.0]\n",
      "[8704, 1440, 10.0, 320]\n",
      "[3584, 1480, 11, 352]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T08:40:13.767396Z",
     "start_time": "2024-08-14T08:40:12.159284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=1)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.maxpool3x3 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 主路径\n",
    "        out = self.conv3x3(x)\n",
    "        \n",
    "        # 残差连接，1x1 卷积\n",
    "        residual = self.conv1x1(x)\n",
    "        \n",
    "        # 计算残差路径和主路径之和\n",
    "        out += residual\n",
    "        \n",
    "        # 最大池化路径\n",
    "        out = self.maxpool3x3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 创建模型实例\n",
    "model = CustomModel()\n",
    "\n",
    "# 检查模型结构\n",
    "print(model)"
   ],
   "id": "7680f3754e53cd5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (conv1x1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T13:02:51.938525Z",
     "start_time": "2024-07-28T13:02:51.933036Z"
    }
   },
   "cell_type": "code",
   "source": "pickle.load(open('./agu/core-i7-7820x.pkl', 'rb'))",
   "id": "ba763681a46ce07a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.3, 8, 16, 11.0, 37.5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:13:27.750291Z",
     "start_time": "2024-07-22T11:13:27.748466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pickle.load(open('./agu/core-i9-13900k.pkl', 'rb'))\n",
    "df"
   ],
   "id": "3ba5b66ed273cbc9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.2, 16, 32, 30, 59.7]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T13:03:21.463026Z",
     "start_time": "2024-07-28T13:03:21.460819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pickle.load(open('./agu/1080Ti.pkl', 'rb'))\n",
    "df"
   ],
   "id": "893e71d8dda18369",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3584, 1582, 11, 352]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:15:14.277259Z",
     "start_time": "2024-07-22T11:15:14.274983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "norm = [7, 32, 32, 40, 60]\n",
    "for i in range(len(norm)):\n",
    "    df[i] /= norm[i]\n",
    "df"
   ],
   "id": "5245b5540d67c5a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10612244897959185, 0.015625, 0.03125, 0.01875, 0.016583333333333332]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:15:36.208024Z",
     "start_time": "2024-07-22T11:15:36.204696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch \n",
    "df = pickle.load(open('./agu/core-i9-13900k.pkl', 'rb'))\n",
    "norm = [7, 32, 32, 40, 60]\n",
    "for i in range(len(norm)):\n",
    "    df[i] /= norm[i]\n",
    "aug_data = torch.tensor(df).float().unsqueeze(0)"
   ],
   "id": "96a3399bfa541ca1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7429, 0.5000, 1.0000, 0.7500, 0.9950]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:19:56.016039Z",
     "start_time": "2024-07-22T11:19:56.013556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = './agu/core-i9-13900k.pkl'\n",
    "a.split('.')[-2]"
   ],
   "id": "5d4935f6e73bf5e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/agu/core-i9-13900k'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T12:36:53.216743Z",
     "start_time": "2024-07-22T12:36:53.197915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle \n",
    "df = pickle.load(open('datasets/cpu/desktop-cpu-core-i7-7820x-fp32.pickle', 'rb'))\n",
    "max_value = 0\n",
    "for key in df.keys():\n",
    "    max_value = max(max_value, df[key].max())\n",
    "max_value"
   ],
   "id": "20a3be6f6fb5c132",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009513392448425292"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "datasets/cpu/desktop-cpu-core-i7-7820x-fp32.pickle",
   "id": "e0a811c0b5b9a1de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T14:24:17.028266Z",
     "start_time": "2024-07-26T14:24:17.025348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dgl import graph\n",
    "\n",
    "def problematic_function():\n",
    "    g = graph([])\n",
    "    g.add_nodes(10)\n",
    "    g.add_edges(list(range(9)), list(range(1, 10)))\n",
    "    return g\n",
    "\n",
    "problematic_function()\n"
   ],
   "id": "f94610dc34c8ddf8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=10, num_edges=9,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T02:53:07.832520Z",
     "start_time": "2024-09-15T02:53:07.826899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class InferenceNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, hw_embed_on, hw_embed_dim, layer_size, determ):\n",
    "        super(InferenceNetwork, self).__init__()\n",
    "        self.num_channel = 3\n",
    "        self.hw_embed_on = hw_embed_on\n",
    "        self.layer_size = layer_size\n",
    "        # 是否是确定性推断\n",
    "        self.determ = determ\n",
    "\n",
    "        # z 编码器，用于将硬件嵌入转化为潜在空间的均值和标准差\n",
    "        self.z_encoder = nn.Sequential(*[\n",
    "            nn.Linear(hw_embed_dim, 10),   # 输入硬件嵌入维度，输出 10 维度\n",
    "            nn.ReLU(),                     # 激活函数 ReLU\n",
    "            nn.Linear(10, 2*(self.layer_size*2+1)*3)  # 输出 2*(layer_size*2+1)*3 维度\n",
    "        ])\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def get_posterior(self, inputs):\n",
    "        # 获取后验分布函数，输入包括 (x, y, hw_embed)\n",
    "        (x, y, hw_embed) = inputs\n",
    "        # 使用 z 编码器对硬件嵌入进行编码，得到 z 的统计值\n",
    "        z_stats = self.z_encoder(hw_embed)\n",
    "        # 从 z_stats 中提取均值，前 (layer_size*2+1)*3 个为均值\n",
    "        mu_z = z_stats[:(self.layer_size*2+1)*3].squeeze()     \n",
    "        # 从 z_stats 中提取标准差，后 (layer_size*2+1)*3 个为标准差\n",
    "        sigma_z = z_stats[(self.layer_size*2+1)*3:].squeeze()  \n",
    "        # 根据均值和经过 softplus 的标准差，生成正态分布\n",
    "        q_z = torch.distributions.Normal(mu_z, self.softplus(sigma_z))\n",
    "\n",
    "        return q_z\n",
    "    \n",
    "    def kl_diagnormal_stdnormal(self, p):\n",
    "        pshape = p.mean.shape\n",
    "        device = p.mean.device\n",
    "        q = torch.distributions.Normal(torch.zeros(pshape, device=device), torch.ones(pshape, device=device))\n",
    "        return torch.distributions.kl.kl_divergence(p, q).to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # 计算后验分布\n",
    "        q_z = self.get_posterior(inputs)\n",
    "        # 计算 KL 散度，使用标准正态分布作为参考分布\n",
    "        kl_z = torch.sum(self.kl_diagnormal_stdnormal(q_z))\n",
    "        # 从后验分布中采样，或者直接取均值（如果是确定性推断）\n",
    "        z = None\n",
    "        kl = 0.\n",
    "\n",
    "        kl = kl + kl_z  # 累积 KL 散度\n",
    "        # 如果不是确定性推断，使用 rsample 从后验分布中采样；否则，使用分布的均值\n",
    "        z_ = q_z.rsample() if not self.determ else q_z.mean \n",
    "        # 从 z_ 中提取权重部分（前 (layer_size*2)*3 个元素）\n",
    "        zw_ = z_[:(self.layer_size*2)*3].squeeze()     \n",
    "        # 从 z_ 中提取偏置部分（后面的元素）\n",
    "        zb_ = z_[(self.layer_size*2)*3:].squeeze()     \n",
    "        # 将权重和偏置保存在字典 z 中\n",
    "        z = {'w':zw_, 'b':zb_}\n",
    "        # 返回采样的权重和偏置，以及 KL 散度\n",
    "        return z, kl"
   ],
   "id": "f1b592fc6213bf4f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.5000, 1.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:20:52.764429Z",
     "start_time": "2024-09-25T14:20:51.919107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# 第一个变量 graph\n",
    "graph = torch.tensor([\n",
    "    [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "    [0., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
    "    [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "    [0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
    "    [0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
    "    [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "    [0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 1.]\n",
    "])\n",
    "\n",
    "# 第二个变量 features\n",
    "features = torch.tensor([\n",
    "    [0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0]\n",
    "])\n",
    "\n",
    "# 检查每一行 features，如果为全 0，则在 graph 的第一行将对应位置的值置为 0\n",
    "for i in range(features.size(0)):\n",
    "    if torch.all(features[i] == 0):\n",
    "        graph[0, i] = 0\n",
    "\n",
    "# 输出修改后的 graph\n",
    "print(graph)"
   ],
   "id": "cd4a6fdf11d32721",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T01:25:27.743214Z",
     "start_time": "2024-10-13T01:25:27.735355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def send_email(subject, body, receiver_email=\"zengyuxiang@hnu.edu.cn\"):\n",
    "    import yagmail\n",
    "    import pickle\n",
    "    import os\n",
    "    # 获得主目录下的邮件授权码\n",
    "    email_code_address = os.path.expanduser('~') + '/qq_smtp_info.pickle'\n",
    "    try:\n",
    "        with open(email_code_address, 'rb') as f:\n",
    "            all_info = pickle.load(f)\n",
    "        sender_email = all_info['email']\n",
    "        sender_password = all_info['password']\n",
    "    except FileNotFoundError:\n",
    "        print(\"非管理员，无法发送邮件\")\n",
    "        return False\n",
    "    try:\n",
    "        yag = yagmail.SMTP(user=sender_email, password=sender_password, host='smtp.qq.com')\n",
    "        yag.send(to=receiver_email, subject=subject, contents=body)\n",
    "        print(\"邮件发送成功!\")\n",
    "    except Exception as e:\n",
    "        print(f\"发送邮件时出错: {e}\")\n"
   ],
   "id": "b4044eefc46f51dc",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T03:32:08.631885Z",
     "start_time": "2024-10-13T03:32:00.157526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    send_email('爱宝宝', '爱宝宝', '22rqwang@stu.edu.cn')"
   ],
   "id": "ce1445a6ecb8d540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "邮件发送成功!\n",
      "邮件发送成功!\n",
      "邮件发送成功!\n",
      "邮件发送成功!\n",
      "邮件发送成功!\n",
      "邮件发送成功!\n",
      "邮件发送成功!\n",
      "邮件发送成功!\n",
      "邮件发送成功!\n",
      "邮件发送成功!\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:59:21.304801Z",
     "start_time": "2024-10-12T16:59:21.302666Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f3f7d5f020ae3586",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:59:49.500442Z",
     "start_time": "2024-10-12T16:59:48.685482Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "64ba44f5299dedb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "邮件发送成功!\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e0a045c44de5a27b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
