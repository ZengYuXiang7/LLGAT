{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-22T08:08:27.519835Z",
     "start_time": "2024-08-22T08:08:26.718764Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:08:28.061744Z",
     "start_time": "2024-08-22T08:08:27.520920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.plotter import MetricsPlotter\n",
    "from utils.logger import Logger\n",
    "from utils.utils import set_settings\n",
    "from data import experiment\n",
    "from utils.config import get_config\n",
    "\n",
    "args = get_config()\n",
    "set_settings(args)\n",
    "# logger plotter\n",
    "exper_detail = f\"Dataset : {args.dataset.upper()}, Model : {args.model}, Train_size : {args.train_size}, Bs : {args.bs}, Rank : {args.rank}, \"\n",
    "exper_detail += f\"Train Device : {args.train_device} \"\n",
    "log_filename = f'Model_{args.model}_T{args.train_size}_R{args.rank}'\n",
    "log = Logger(log_filename, exper_detail, args)\n",
    "plotter = MetricsPlotter(log_filename, args)\n",
    "args.log = log\n",
    "log(str(args.__dict__))"
   ],
   "id": "16d41c26aae5abe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;2;151;200;129m|2024-08-22 16:08:28| \u001B[0m\u001B[1m{\n",
      "     'att': 0, 'bs': 32, 'classification': False, 'cross': 0, 'dataset': cpu,\n",
      "     'debug': False, 'decay': 0.0001, 'density': 0.8, 'device': cpu, 'device_name': core-i7-7820x,\n",
      "     'epochs': 1000, 'eval_device': desktop-cpu-core-i9-13900k-fp32, 'experiment': False, 'graph_encoder': gat, 'heads': 0,\n",
      "     'inductive': False, 'llm': 1, 'logger': None, 'loss_func': L1Loss, 'lr': 0.001,\n",
      "     'model': ours, 'num_preds': 1, 'num_windows': 12, 'op_encoder': embed, 'optim': AdamW,\n",
      "     'order': 4, 'path': ./datasets/, 'patience': 100, 'program_test': False, 'rank': 100,\n",
      "     'record': True, 'rounds': 5, 'seed': 0, 'train_device': desktop-cpu-core-i7-7820x-fp32, 'train_size': 500,\n",
      "     'verbose': 0, 'visualize': True,\n",
      "}\u001B[0m\n",
      "\u001B[1;38;2;151;200;129m|2024-08-22 16:08:28| \u001B[0m\u001B[1m{'classification': False, 'visualize': True, 'inductive': False, 'bs': 32, 'lr': 0.001, 'decay': 0.0001, 'loss_func': 'L1Loss', 'optim': 'AdamW', 'path': './datasets/', 'dataset': 'cpu', 'train_size': 500, 'density': 0.8, 'logger': 'None', 'model': 'ours', 'rank': 100, 'num_windows': 12, 'num_preds': 1, 'seed': 0, 'rounds': 5, 'epochs': 1000, 'patience': 100, 'verbose': 0, 'device': 'cpu', 'debug': False, 'experiment': False, 'program_test': False, 'record': True, 'train_device': 'desktop-cpu-core-i7-7820x-fp32', 'device_name': 'core-i7-7820x', 'llm': 1, 'op_encoder': 'embed', 'order': 4, 'heads': 0, 'graph_encoder': 'gat', 'eval_device': 'desktop-cpu-core-i9-13900k-fp32', 'att': 0, 'cross': 0, 'log': <utils.logger.Logger object at 0x7fd5e89fe370>}\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:08:28.830459Z",
     "start_time": "2024-08-22T08:08:28.062989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from train_model import Model\n",
    "from data import DataModule\n",
    "\n",
    "# Initialize\n",
    "exper = experiment(args)\n",
    "datamodule = DataModule(exper, args)\n",
    "model = Model(datamodule, args)"
   ],
   "id": "43a8b2e6217444de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desktop-cpu-core-i7-7820x-fp32.pickle\n",
      "\u001B[1;38;2;151;200;129m|2024-08-22 16:08:28| \u001B[0m\u001B[1mTrain_length : 500 Valid_length : 1528 Test_length : 13256 Max_value : 0.01\u001B[0m\n",
      "加载存储数据 tensor([[0.6143, 0.2500, 0.5000, 0.2750, 0.3750]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zengyuxiang/opt/anaconda3/lib/python3.8/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:08:28.908649Z",
     "start_time": "2024-08-22T08:08:28.831519Z"
    }
   },
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load('./checkpoints/ours/Model_ours_gpu_S200_R100_O3_round_4.pt', map_location=torch.device('cpu')))",
   "id": "83d7f74d67ca95dc",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/ours/Model_ours_T50_R300_round_0.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-f9e38fee2148>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'checkpoints/ours/Model_ours_T50_R300_round_0.pt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m    996\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    997\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 998\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    999\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1000\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    444\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 445\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    446\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    447\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    424\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    425\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 426\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    428\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'checkpoints/ours/Model_ours_T50_R300_round_0.pt'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:08:28.910441Z",
     "start_time": "2024-08-22T08:08:28.910378Z"
    }
   },
   "cell_type": "code",
   "source": "idx = 32",
   "id": "5c2cb9f24fad837",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:08:28.911135Z",
     "start_time": "2024-08-22T08:08:28.911086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_input = datamodule.train_loader.dataset[idx]\n",
    "graph, features, values = sample_input\n",
    "print(graph, features)\n",
    "print(model(graph, features.reshape(1, -1)))"
   ],
   "id": "237e8f0eb6cd632a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.model.aug_data",
   "id": "3d74943212a62d77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b1ce613a716f7391",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_embeds_importance(model, sample_input):\n",
    "    import torch\n",
    "    \n",
    "    graph, features, values = sample_input\n",
    "    features = features.reshape(1, -1).long()\n",
    "    \n",
    "    # 清除模型中所有参数的梯度\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # 确保 info_embeds 和 graph_embeds 的梯度可以计算\n",
    "    batch_size = features.shape[0]\n",
    "    aug_data_repeated = model.model.aug_data.expand(batch_size, -1).to(model.model.args.device)\n",
    "    info_embeds = model.model.info_encoder(aug_data_repeated)\n",
    "    graph_embeds = model.model.graph_encoder(graph, features)\n",
    "    \n",
    "    # 确保在前向传播之前设置 requires_grad=True\n",
    "    info_embeds.requires_grad_(True)\n",
    "    graph_embeds.requires_grad_(True)\n",
    "    \n",
    "    # 在非叶子张量上保留梯度\n",
    "    info_embeds.retain_grad()\n",
    "    graph_embeds.retain_grad()\n",
    "    \n",
    "    # 组合嵌入，进行前向传播\n",
    "    embeds = torch.cat([graph_embeds, info_embeds], dim=1)\n",
    "    output = model.model.predictor(embeds)\n",
    "    \n",
    "    # 使用人为定义的损失函数，比如对输出的简单加权平均\n",
    "    loss = output.mean()  # 简单的均值作为损失\n",
    "    \n",
    "    # 反向传播计算损失的梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 获取两个嵌入的梯度并计算它们的重要性\n",
    "    info_importance = info_embeds.grad.abs().sum().item()\n",
    "    graph_importance = graph_embeds.grad.abs().sum().item()\n",
    "    \n",
    "    total_importance = info_importance + graph_importance\n",
    "    graph_importance /= total_importance\n",
    "    info_importance /= total_importance\n",
    "    \n",
    "    print(\"LLMs Embeds Importance:\", info_importance)\n",
    "    print(\"Graph Embeds Importance:\", graph_importance)\n",
    "    return graph_importance, info_importance\n",
    "_, _ = get_embeds_importance(model, sample_input=datamodule.train_loader.dataset[idx])"
   ],
   "id": "8bda4641a48ae2ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8e136f0d5a21b0d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e0cd2bbc521f7c0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_node_importance(model, sample_input):\n",
    "    graph, features, values = sample_input\n",
    "    features = features.reshape(1, -1).long()\n",
    "    g, feats = graph, model.model.graph_encoder.dnn_embedding(features).reshape(features.shape[0] * 9, -1)\n",
    "    attention_weights = []\n",
    "    for i, (layer, norm, act) in enumerate(zip(model.model.graph_encoder.layers, model.model.graph_encoder.norms, model.model.graph_encoder.acts)):\n",
    "        # 获取 GAT 的注意力权重\n",
    "        feats, attn = layer(g, feats, get_attention=True)\n",
    "        feats = feats.mean(dim=1)  # 聚合多个头的输出\n",
    "        feats = norm(feats)\n",
    "        feats = act(feats)\n",
    "        attention_weights.append(attn)\n",
    "    batch_sizes = torch.as_tensor(g.batch_num_nodes()).to(model.model.args.device)  # 每个图的节点数\n",
    "    first_nodes_idx = torch.cumsum(torch.cat((torch.tensor([0]).to(model.model.args.device), batch_sizes[:-1])), dim=0)  # 使用torch.cat来连接Tensor\n",
    "    first_node_features = feats[first_nodes_idx]\n",
    "    return first_node_features, attention_weights\n",
    "first_node_features, attention_weights = get_node_importance(model, sample_input = datamodule.train_loader.dataset[idx])"
   ],
   "id": "fca06f8eda53fade",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph",
   "id": "c55fb82428831682",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(attention_weights)",
   "id": "6a3c22bc85ba109",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "global_node_attention = attention_weights[-1] \n",
    "global_node_attention.shape"
   ],
   "id": "15ff35553ad13ba0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def aggregate_attention(global_node_attention):\n",
    "#     # 假设 global_node_attention 的形状是 [num_edges, num_heads, 1]\n",
    "#     # 对注意力权重在所有头上取平均\n",
    "#     mean_attention = global_node_attention.mean(dim=1)  # [num_edges, 1]\n",
    "# \n",
    "#     # 初始化节点的重要性\n",
    "#     node_importance = mean_attention.squeeze(-1)  # 移除最后的单一维度，得到 [num_edges]\n",
    "# \n",
    "#     return node_importance\n",
    "# \n",
    "# # 使用聚合函数计算节点的重要性\n",
    "# node_importance = aggregate_attention(global_node_attention)\n",
    "# print(\"Node importance to the global node:\", node_importance.detach().cpu().numpy())"
   ],
   "id": "8affaf772d1fa29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# def aggregate_node_attention(graph, global_node_attention):\n",
    "#     # 获取图中的节点数和边数\n",
    "#     num_nodes = graph.number_of_nodes()\n",
    "#     num_edges = graph.number_of_edges()\n",
    "# \n",
    "#     # 假设 global_node_attention 的形状是 [num_edges, num_heads, 1]\n",
    "#     mean_attention = global_node_attention.mean(dim=1).squeeze(-1)  # [num_edges]\n",
    "#     \n",
    "#     print(mean_attention)\n",
    "#     \n",
    "#     # 初始化每个节点的注意力权重为零\n",
    "#     node_importance = torch.zeros(num_nodes, device=mean_attention.device)\n",
    "#     print(node_importance)\n",
    "#     # 遍历每条边，将注意力权重聚合到对应的节点上\n",
    "#     for edge_idx in range(num_edges):\n",
    "#         src, dst = graph.find_edges(edge_idx)  # 获取边的起始节点和目标节点\n",
    "#         # 累加目标节点（全局节点）的注意力权重\n",
    "#         node_importance[dst] += mean_attention[edge_idx]\n",
    "#         print(dst, node_importance[dst])\n",
    "#     # print(node_importance)\n",
    "#     \n",
    "#     return node_importance\n",
    "# \n",
    "# # 使用函数计算每个节点对全局节点的重要性\n",
    "# node_importance = aggregate_node_attention(graph, global_node_attention)\n",
    "# print(\"Node importance to the global node:\", node_importance.detach().cpu().numpy())"
   ],
   "id": "cda914e1af077bde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_device_feature_importance(model, sample_input):\n",
    "    import torch\n",
    "    \n",
    "    # 清除模型中所有参数的梯度\n",
    "    model.zero_grad()\n",
    "    \n",
    "    graph, features, values = sample_input\n",
    "    \n",
    "    # 获取 info_importance\n",
    "    _, info_importance = get_embeds_importance(model, sample_input)\n",
    "    \n",
    "    # 设置 aug_data 为 requires_grad=True\n",
    "    model.model.aug_data.requires_grad = True\n",
    "    \n",
    "    # 前向传播计算输出 y\n",
    "    features = features.reshape(1, -1).long()\n",
    "    output = model(graph, features)\n",
    "    \n",
    "    # 反向传播计算每个输入特征的梯度\n",
    "    output.backward()\n",
    "    \n",
    "    # 获取 aug_data 的梯度并计算重要性\n",
    "    aug_data_importance = model.model.aug_data.grad.abs()\n",
    "    \n",
    "    # 标准化重要性，使其和为1\n",
    "    aug_data_importance = aug_data_importance / aug_data_importance.sum()\n",
    "    \n",
    "    # 打印 aug_data 中每个元素的重要性\n",
    "    print(\"Importance of each element in aug_data:\", aug_data_importance.detach().numpy())\n",
    "    \n",
    "    # 计算每个 aug_data 元素在整个模型中的重要性\n",
    "    each_device_info_importance = info_importance * aug_data_importance\n",
    "    each_device_info_importance = each_device_info_importance.squeeze(0).detach().numpy()\n",
    "    print(\"Overall importance of each element in aug_data to the model:\")\n",
    "    for i in range(len(each_device_info_importance)):\n",
    "        print(f\"LLMs features-{i} : {each_device_info_importance[i]:.4f}\", )\n",
    "    \n",
    "get_device_feature_importance(model = model, sample_input = datamodule.train_loader.dataset[idx])"
   ],
   "id": "d687e502ba1a308f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_node_importance(model, sample_input):\n",
    "    graph, features, values = sample_input\n",
    "    features = features.reshape(1, -1).long()\n",
    "    g, feats = graph, model.model.graph_encoder.dnn_embedding(features).reshape(features.shape[0] * 9, -1)\n",
    "    attention_weights = []\n",
    "    for i, (layer, norm, act) in enumerate(zip(model.model.graph_encoder.layers, model.model.graph_encoder.norms, model.model.graph_encoder.acts)):\n",
    "        # 获取 GAT 的注意力权重\n",
    "        feats, attn = layer(g, feats, get_attention=True)\n",
    "        feats = feats.mean(dim=1)  # 聚合多个头的输出\n",
    "        feats = norm(feats)\n",
    "        feats = act(feats)\n",
    "        attention_weights.append(attn)\n",
    "    batch_sizes = torch.as_tensor(g.batch_num_nodes()).to(model.model.args.device)  # 每个图的节点数\n",
    "    first_nodes_idx = torch.cumsum(torch.cat((torch.tensor([0]).to(model.model.args.device), batch_sizes[:-1])), dim=0)  # 使用torch.cat来连接Tensor\n",
    "    first_node_features = feats[first_nodes_idx]\n",
    "    return first_node_features, attention_weights\n",
    "first_node_features, attention_weights = get_node_importance(model, sample_input = datamodule.train_loader.dataset[idx])\n",
    "\n",
    "\n",
    "def aggregate_node_attention(model, sample_input, graph, global_node_attention):\n",
    "    # 获取图中的节点数和边数\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    num_edges = graph.number_of_edges()\n",
    "\n",
    "    # 假设 global_node_attention 的形状是 [num_edges, num_heads, 1]\n",
    "    mean_attention = global_node_attention.mean(dim=1).squeeze(-1)  # [num_edges]\n",
    "    \n",
    "    print(\"Mean attention per edge:\", mean_attention)\n",
    "    \n",
    "    # 初始化每个节点的注意力权重为零\n",
    "    node_importance = torch.zeros(num_nodes, device=mean_attention.device)\n",
    "    \n",
    "    # 遍历每条边，将注意力权重聚合到对应的节点上\n",
    "    for edge_idx in range(num_edges):\n",
    "        src, dst = graph.find_edges(edge_idx)  # 获取边的起始节点和目标节点\n",
    "        if dst == 0:\n",
    "            # 累加目标节点的注意力权重\n",
    "            node_importance[src] += mean_attention[edge_idx]\n",
    "            print(f\"Edge {edge_idx:2d}: src={src}, dst={dst}, Attention={mean_attention[edge_idx]:.4f}, accumulated importance={node_importance[src]}\")\n",
    "    \n",
    "    # 最后可以对 node_importance 进行归一化处理，使其值在合理范围内\n",
    "    node_importance = node_importance / node_importance.sum()\n",
    "    \n",
    "    print(\"Node importance to the global node:\\n\", node_importance.detach().cpu().numpy())\n",
    "\n",
    "    # 获取 graph_importance\n",
    "    graph_importance, _ = get_embeds_importance(model, sample_input)\n",
    "    each_device_node_importance = graph_importance * node_importance\n",
    "    each_device_node_importance = each_device_node_importance.detach().numpy()\n",
    "    _, key, values = sample_input\n",
    "    print(\"Overall importance of each element in graph to the Global Node:\")\n",
    "    for i in range(len(key)):\n",
    "        print(f\"Key={key[i].item()}: {each_device_node_importance[i]:.4f}\")\n",
    "    return node_importance\n",
    "\n",
    "# 使用函数计算每个节点对全局节点的重要性\n",
    "node_importance = aggregate_node_attention(model, sample_input, graph, global_node_attention)"
   ],
   "id": "b7070f8e1a2b136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    0 con1 1 con3 2 max3 3 input 4 output 5 None\n",
    "\"\"\"\n",
    "op_name = ['con1', 'con3', 'max3', 'input', 'output', 'None']"
   ],
   "id": "33eb23f73f183dbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T07:11:34.990947Z",
     "start_time": "2024-08-26T07:11:34.989183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    CPU Clock Frequency, Maximum Turbo Boost Frequency, Number of Cores, Number of Threads, Level 3 Cache, Maximum Memory Bandwidth\n",
    "\"\"\"\n",
    "device_fetures = ['CPU Clock Frequency', 'Maximum Turbo Boost Frequency', 'Number of Cores', 'Number of Threads', 'Level 3 Cache', ', Maximum Memory Bandwidth']"
   ],
   "id": "ec79008400ebd138",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e32e53fc65afcca5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
